{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KB-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "sys.path.append(os.path.dirname(find_dotenv()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the file_handler.py file\n",
    "from py_scripts.file_handler import read_csv_file\n",
    "\n",
    "#Read the data\n",
    "X, Y = read_csv_file(\"clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_scripts.ner_util.ner_system as ner_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data \n",
    "X, Y = read_csv_file(\"clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state=104\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=random_state, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=0.5,random_state=random_state,shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "kb_tokenizer = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
    "kb_model = AutoModel.from_pretrained('KB/bert-base-swedish-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KB_BERT(nn.Module):\n",
    "    def __init__(self, seq_labeler):\n",
    "        super().__init__() \n",
    "\n",
    "        p = seq_labeler.params\n",
    "        self.bert = kb_model\n",
    "\n",
    "        # Output unit.\n",
    "        self.top_layer = nn.Linear(self.bert.config.hidden_size, seq_labeler.n_labels)\n",
    "\n",
    "    def forward(self, words):\n",
    "        outputs = self.bert(words)\n",
    "        res = outputs[0]\n",
    "        return self.top_layer(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining NER Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERParameters():\n",
    "\n",
    "    # Random seed, for reproducibility.\n",
    "    random_seed = 0\n",
    "    \n",
    "    # cuda or cpu\n",
    "    device = 'mps'    \n",
    "    \n",
    "    #Tagging scheme used in data: IO or IOB (Inside-Outside-Beginning)\n",
    "    tagging_scheme=None\n",
    "    \n",
    "    # Training parameters\n",
    "    n_epochs = 1\n",
    "    batch_size = 16   \n",
    "    learning_rate = 0.0001\n",
    "    weight_decay = 0\n",
    "\n",
    "    # Word dropout rate.\n",
    "    word_dropout_prob = 0.0\n",
    "\n",
    "    bert_max_len = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_system = ner_util.SequenceLabeler(NERParameters(), KB_BERT, bert_tokenizer=AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased'))\n",
    "\n",
    "ner_system.fit(X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_system.evaluate_model(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
