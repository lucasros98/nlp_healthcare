{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import sys\n",
    "from torch import nn\n",
    "\n",
    "sys.path.append(os.path.dirname(find_dotenv()))\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the file_handler\n",
    "from py_scripts.file_handler import read_csv_file\n",
    "\n",
    "#Import the NER system\n",
    "import py_scripts.ner_util.ner_system as ner_util\n",
    "\n",
    "#Import evaluation functions\n",
    "import py_scripts.ner_util.evaluation as evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data \n",
    "X, Y = read_csv_file(\"clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the BERT tokenizer on clincial text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the tokenizer by finding all the unknown tokens in the data and printing them\n",
    "from py_scripts.data import print_unknown_tokens\n",
    "\n",
    "print_unknown_tokens(tokenizer, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Ratio of train, validation and test\n",
    "train_ratio = 0.8\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "#Random state - For reproducibility\n",
    "random_state=104\n",
    "\n",
    "#Split data into train, validation and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1-train_ratio, random_state=random_state)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=test_ratio/(test_ratio+validation_ratio), random_state=random_state)\n",
    "\n",
    "#Get the precentage of the data that should be used for training\n",
    "try:\n",
    "    precentage = float(float(sys.argv[1])/100) if len(sys.argv) > 1 and sys.argv[1] != \"None\" else 1.0\n",
    "except:\n",
    "    print(\"Error occured while parsing the precentage from the sys args. Please check the sys args.\")\n",
    "    precentage = 1.0\n",
    "\n",
    "X_train = X_train[:int(len(X_train)*precentage)]\n",
    "Y_train = Y_train[:int(len(Y_train)*precentage)]\n",
    "\n",
    "print(\"Using \" + str(precentage*100) + \"% of the data for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the length of the data\n",
    "print(\"Length of the data:\")\n",
    "print(\"Train: \" + str(len(X_train)))\n",
    "print(\"Validation: \" + str(len(X_val)))\n",
    "print(\"Test: \" + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, seq_labeler):\n",
    "        super().__init__() \n",
    "\n",
    "        # BERT model.\n",
    "        self.bert = bert_model\n",
    "\n",
    "        # Output unit.\n",
    "        self.top_layer = nn.Linear(self.bert.config.hidden_size, seq_labeler.n_labels)\n",
    "\n",
    "    def forward(self, words):\n",
    "        outputs = self.bert(words)\n",
    "        res = outputs[0]\n",
    "        return self.top_layer(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining NER Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import NER parameters from parameters.py\n",
    "from parameters import NERParameters\n",
    "\n",
    "params = NERParameters()\n",
    "\n",
    "#Update the parameters if needed\n",
    "params.tagging_scheme = \"IO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_system = ner_util.SequenceLabeler(params, Model, bert_tokenizer=tokenizer)\n",
    "\n",
    "ner_system.fit(X_train, Y_train, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the system\n",
    "\n",
    "Evaluate the sytem on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_system.evaluate_model(X_test,Y_test)\n",
    "\n",
    "evaluation.print_examples(ner_system, 'sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print some examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "947566739ad5f995ef683c347463316d267e00143e5dd2f059640c7a26e2b5e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
